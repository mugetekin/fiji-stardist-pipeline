"""
Merge per-sample CSVs into ALL_* summaries and write an HTML report.

Usage:
    python -m src.merge_reports --outputs_dir outputs/growth/_examples
Optional:
    --batch_map path/to/batch_map.csv     # CSV with columns: Sample,Batch
    --norm median_center|zscore|none      # default: median_center
"""
from __future__ import annotations

import argparse
from pathlib import Path
import base64

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


def _read_if_exists(path: Path) -> pd.DataFrame | None:
    try:
        if path.exists():
            return pd.read_csv(path)
    except Exception:
        pass
    return None


def _save_bar(df, x, y, title, out_png):
    plt.figure(figsize=(10, 5))
    plt.bar(df[x].astype(str), df[y].values)
    plt.xticks(rotation=45, ha="right")
    plt.title(title)
    plt.tight_layout()
    plt.savefig(out_png, dpi=160)
    plt.close()


def _save_scatter(df, x, y, title, out_png):
    plt.figure(figsize=(6, 5))
    plt.scatter(df[x].values, df[y].values)
    plt.xlabel(x)
    plt.ylabel(y)
    plt.title(title)
    plt.tight_layout()
    plt.savefig(out_png, dpi=160)
    plt.close()


def _save_stacked_regions(region_df, out_png):
    # Expect columns: Sample, Region, N
    pvt = region_df.pivot_table(
        index="Sample", columns="Region", values="N", aggfunc="sum", fill_value=0
    )
    pvt = pvt.sort_index()
    plt.figure(figsize=(10, 6))
    bottom = np.zeros(len(pvt))
    for col in pvt.columns:
        plt.bar(pvt.index.astype(str), pvt[col].values, bottom=bottom, label=str(col))
        bottom += pvt[col].values
    plt.xticks(rotation=45, ha="right")
    plt.title("Cell counts per region (stacked)")
    plt.legend()
    plt.tight_layout()
    plt.savefig(out_png, dpi=160)
    plt.close()


def _img_to_data_uri(path: Path) -> str:
    with open(path, "rb") as f:
        b = f.read()
    b64 = base64.b64encode(b).decode("ascii")
    mime = "image/png" if path.suffix.lower() == ".png" else "image/jpeg"
    return f"data:{mime};base64,{b64}"


def _write_html_report(out_dir: Path, overall_csv: Path | None, regions_csv: Path | None, plot_paths: list[Path]):
    html = []
    html.append("<html><head><meta charset='utf-8'><title>Confocal Batch Report</title>")
    html.append(
        """
    <style>
      body{font-family: Arial, sans-serif; margin: 24px; }
      h1,h2{margin: 0 0 12px 0;}
      .grid{display:grid; grid-template-columns: repeat(auto-fit,minmax(320px,1fr)); gap:12px;}
      .card{border:1px solid #ddd; border-radius:8px; padding:12px;}
      table{border-collapse: collapse; width:100%;}
      th,td{border:1px solid #ddd; padding:6px; font-size: 13px;}
      th{background:#f6f6f6;}
      code{background:#f2f2f2; padding:2px 4px; border-radius:4px;}
    </style>
    """
    )
    html.append("</head><body>")
    html.append("<h1>Confocal Analysis â€“ Merged Report</h1>")

    # Links to CSVs
    html.append("<div class='card'><h2>Downloads</h2><ul>")
    if overall_csv and overall_csv.exists():
        html.append(f"<li><a href='{overall_csv.name}' download>{overall_csv.name}</a></li>")
    if regions_csv and regions_csv.exists():
        html.append(f"<li><a href='{regions_csv.name}' download>{regions_csv.name}</a></li>")
    html.append("</ul></div>")

    # Plots
    if plot_paths:
        html.append("<h2>Plots</h2><div class='grid'>")
        for p in plot_paths:
            if p.exists():
                uri = _img_to_data_uri(p)
                html.append(f"<div class='card'><h3>{p.name}</h3><img src='{uri}' style='width:100%'></div>")
        html.append("</div>")

    html.append("<p style='margin-top:24px;color:#777'>Generated by src.merge_reports</p>")
    html.append("</body></html>")

    out_html = out_dir / "report.html"
    with open(out_html, "w", encoding="utf-8") as f:
        f.write("\n".join(html))
    print(f"[report] wrote {out_html}")


def _load_batch_map(batch_map_path: str | None, samples: list[str]) -> pd.DataFrame:
    if batch_map_path and Path(batch_map_path).exists():
        bm = pd.read_csv(batch_map_path)
        if not {"Sample", "Batch"}.issubset(bm.columns):
            raise ValueError("batch_map must have columns: Sample,Batch")
        return bm[["Sample", "Batch"]].drop_duplicates()
    # heuristic: prefix before first underscore
    rows = []
    for s in samples:
        parts = s.split("_")
        batch = parts[0] if len(parts) > 1 else s
        rows.append({"Sample": s, "Batch": batch})
    return pd.DataFrame(rows)


def _add_batch_and_normalize(all_overall: pd.DataFrame, batch_map: pd.DataFrame, method: str = "median_center") -> pd.DataFrame:
    df = all_overall.copy()
    if "Sample" not in df.columns:
        if "Prefix" in df.columns:
            df["Sample"] = df["Prefix"].apply(lambda p: Path(str(p)).name)
        else:
            raise ValueError("Cannot infer Sample column in ALL_counts_overall.csv")
    df = df.merge(batch_map, on="Sample", how="left")

    norm_cols = [c for c in ["Sox2_pos_percent", "Alexa_pos_percent", "Cy3_pos_percent"] if c in df.columns]
    if not norm_cols:
        return df

    if method == "median_center":
        for c in norm_cols:
            global_med = df[c].median()
            df[c + "_norm"] = df[c]
            for b, sub in df.groupby("Batch"):
                med = sub[c].median()
                df.loc[sub.index, c + "_norm"] = sub[c] - med + global_med
    elif method == "zscore":
        for c in norm_cols:
            df[c + "_norm"] = df[c]
            for b, sub in df.groupby("Batch"):
                mu = sub[c].mean()
                sd = sub[c].std(ddof=1) if len(sub) > 1 else 1.0
                sd = sd if np.isfinite(sd) and sd > 0 else 1.0
                df.loc[sub.index, c + "_norm"] = (sub[c] - mu) / sd
    elif method == "none":
        pass
    else:
        raise ValueError(f"Unknown normalization method: {method}")
    return df


def main():
    ap = argparse.ArgumentParser(description="Merge per-sample CSVs and write report.html")
    ap.add_argument("--outputs_dir", required=True, help="Directory containing per-sample CSVs")
    ap.add_argument("--batch_map", default=None, help="CSV with columns Sample,Batch (optional)")
    ap.add_argument("--norm", default="median_center", choices=["median_center", "zscore", "none"], help="Batch normalization")
    args = ap.parse_args()

    out_dir = Path(args.outputs_dir)
    if not out_dir.exists():
        raise SystemExit(f"outputs_dir not found: {out_dir}")

    # Gather all per-sample CSVs
        # Gather all per-sample CSVs
    ov_csvs = sorted(out_dir.glob("*_counts_overall.csv"))
    reg_csvs = sorted(out_dir.glob("*_counts_by_region.csv"))

    # --- overall files ---
    overall_rows = [df for df in (_read_if_exists(p) for p in ov_csvs) if df is not None]

    # --- region files (ensure Sample column even if missing) ---
    region_rows = []
    for p in reg_csvs:
        df = _read_if_exists(p)
        if df is None:
            continue
        if "Sample" not in df.columns:
            # infer from filename: <sample>_counts_by_region.csv
            sample = p.name.replace("_counts_by_region.csv", "")
            df = df.copy()
            df["Sample"] = sample
        region_rows.append(df)

    all_overall_path = all_regions_path = None
    plots: list[Path] = []

    if overall_rows:
        all_overall = pd.concat(overall_rows, ignore_index=True)
        # Ensure Sample column
        if "Sample" not in all_overall.columns:
            if "Prefix" in all_overall.columns:
                all_overall["Sample"] = all_overall["Prefix"].apply(lambda p: Path(str(p)).name)
        all_overall_path = out_dir / "ALL_counts_overall.csv"
        all_overall.to_csv(all_overall_path, index=False)
        print(f"[merge] wrote {all_overall_path}")

        # Normalization
        if args.norm != "none":
            bm = _load_batch_map(args.batch_map, list(all_overall["Sample"].astype(str)))
            aon = _add_batch_and_normalize(all_overall, bm, method=args.norm)
            aon_path = out_dir / "ALL_counts_overall_normalized.csv"
            aon.to_csv(aon_path, index=False)
            print(f"[merge] wrote {aon_path}")

        # Plots
        if "Sox2_pos_percent" in all_overall.columns:
            p = out_dir / "plot_sox2_percent_per_sample.png"
            _save_bar(all_overall, "Sample", "Sox2_pos_percent", "Sox2+ (%) per sample", str(p))
            plots.append(p)
        if "Total_cells" in all_overall.columns:
            p = out_dir / "plot_total_cells_per_sample.png"
            _save_bar(all_overall, "Sample", "Total_cells", "Total cells per sample", str(p))
            plots.append(p)
        if {"Alexa_pos_percent", "Cy3_pos_percent"}.issubset(all_overall.columns):
            p = out_dir / "plot_alexa_vs_cy3_percent.png"
            _save_scatter(all_overall, "Alexa_pos_percent", "Cy3_pos_percent", "Alexa% vs Cy3% (raw)", str(p))
            plots.append(p)

    if region_rows:
        all_regions = pd.concat(region_rows, ignore_index=True)
        all_regions_path = out_dir / "ALL_counts_by_region.csv"
        all_regions.to_csv(all_regions_path, index=False)
        print(f"[merge] wrote {all_regions_path}")

        p = out_dir / "plot_cells_by_region_stacked.png"
        _save_stacked_regions(all_regions, str(p))
        plots.append(p)

    _write_html_report(out_dir, all_overall_path, all_regions_path, plots)

    print("[merge] done.")


if __name__ == "__main__":
    main()
